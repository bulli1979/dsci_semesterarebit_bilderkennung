{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce172c92",
   "metadata": {},
   "source": [
    "# üîß **PROBLEMBEHEBUNG UND DIAGNOSE**\n",
    "\n",
    "Dieses Notebook enth√§lt Diagnose-Tools und L√∂sungsvorschl√§ge f√ºr Probleme, die bei der Evaluation auftreten k√∂nnen.\n",
    "\n",
    "**Hinweis:** Dieses Notebook ist f√ºr die Problembehebung gedacht und sollte nicht Teil der finalen Semesterarbeit sein.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7418ae75",
   "metadata": {},
   "source": [
    "## üîç Diagnose: Datenanzahl pr√ºfen\n",
    "\n",
    "Diese Zelle zeigt, wie viele Bilder wo gefunden wurden und ob die Daten aktuell sind.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "d9bccbc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DATEN-DIAGNOSE\n",
      "======================================================================\n",
      "\n",
      "1. Extrahierte Bilder (extracted/):\n",
      "   GESAMT              :    0 Bilder\n",
      "\n",
      "2. ZIP-Dateien:\n",
      "   ‚úì training_Baumstruktur.zip: 0.54 MB\n",
      "   ‚úì testing_Baumstruktur.zip: 0.14 MB\n",
      "\n",
      "3. Entpackte Baumstruktur (Baumstruktur/):\n",
      "   ‚úì Train-Ordner: Baumstruktur\\Baumstruktur_train\n",
      "      schraubenschluessel :   66 Bilder\n",
      "      schraubenzieher     :   93 Bilder\n",
      "      seidenschneider     :   90 Bilder\n",
      "      GESAMT              :  249 Bilder\n",
      "   ‚úì Test-Ordner: Baumstruktur\\Baumstruktur_test\n",
      "      schraubenschluessel :   16 Bilder\n",
      "      schraubenzieher     :   24 Bilder\n",
      "      seidenschneider     :   23 Bilder\n",
      "      GESAMT              :   63 Bilder\n",
      "\n",
      "4. Vergleich und Empfehlungen:\n",
      "   ‚ö†Ô∏è HINWEIS: 312 Bilder mehr in Baumstruktur als in extracted/\n",
      "      ‚Üí Dies kann passieren, wenn Bilder mehrfach extrahiert wurden\n",
      "      ‚Üí Oder wenn die ZIP-Dateien neuere Daten enthalten\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# DIAGNOSE: Pr√ºfe Datenanzahl und -qualit√§t\n",
    "# ============================================================================\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"DATEN-DIAGNOSE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Initialisiere Variablen\n",
    "total_extracted = 0\n",
    "total_train = 0\n",
    "total_test = 0\n",
    "\n",
    "# 1. Pr√ºfe extracted-Ordner (aktuellste Daten)\n",
    "extracted_path = Path('extracted')\n",
    "if extracted_path.exists():\n",
    "    print(\"\\n1. Extrahierte Bilder (extracted/):\")\n",
    "    for klasse in ['schraubenschluessel', 'schraubenzieher', 'seidenschneider']:\n",
    "        klasse_path = extracted_path / klasse\n",
    "        if klasse_path.exists():\n",
    "            count = len(list(klasse_path.glob('*.*')))\n",
    "            total_extracted += count\n",
    "            print(f\"   {klasse:20s}: {count:4d} Bilder\")\n",
    "    print(f\"   {'GESAMT':20s}: {total_extracted:4d} Bilder\")\n",
    "else:\n",
    "    print(\"\\n1. Extrahierte Bilder: ‚ùå Ordner 'extracted' existiert nicht!\")\n",
    "    print(\"   ‚Üí F√ºhren Sie zuerst das Objektextraktions-Notebook aus!\")\n",
    "\n",
    "# 2. Pr√ºfe ZIP-Dateien\n",
    "print(\"\\n2. ZIP-Dateien:\")\n",
    "zip_train = Path('training_Baumstruktur.zip')\n",
    "zip_test = Path('testing_Baumstruktur.zip')\n",
    "\n",
    "if zip_train.exists():\n",
    "    size_mb = zip_train.stat().st_size / 1024 / 1024\n",
    "    print(f\"   ‚úì training_Baumstruktur.zip: {size_mb:.2f} MB\")\n",
    "else:\n",
    "    print(f\"   ‚ùå training_Baumstruktur.zip: FEHLT\")\n",
    "    print(\"      ‚Üí F√ºhren Sie das Objektextraktions-Notebook aus, um ZIP zu erstellen!\")\n",
    "\n",
    "if zip_test.exists():\n",
    "    size_mb = zip_test.stat().st_size / 1024 / 1024\n",
    "    print(f\"   ‚úì testing_Baumstruktur.zip: {size_mb:.2f} MB\")\n",
    "else:\n",
    "    print(f\"   ‚ùå testing_Baumstruktur.zip: FEHLT\")\n",
    "    print(\"      ‚Üí F√ºhren Sie das Objektextraktions-Notebook aus, um ZIP zu erstellen!\")\n",
    "\n",
    "# 3. Pr√ºfe entpackte Baumstruktur\n",
    "print(\"\\n3. Entpackte Baumstruktur (Baumstruktur/):\")\n",
    "baumstruktur_path = Path('Baumstruktur')\n",
    "if baumstruktur_path.exists():\n",
    "    train_path = baumstruktur_path / 'Baumstruktur_train'\n",
    "    test_path = baumstruktur_path / 'Baumstruktur_test'\n",
    "    \n",
    "    if train_path.exists():\n",
    "        print(f\"   ‚úì Train-Ordner: {train_path}\")\n",
    "        for klasse_dir in train_path.iterdir():\n",
    "            if klasse_dir.is_dir():\n",
    "                count = len(list(klasse_dir.glob('*.*')))\n",
    "                total_train += count\n",
    "                print(f\"      {klasse_dir.name:20s}: {count:4d} Bilder\")\n",
    "        print(f\"      {'GESAMT':20s}: {total_train:4d} Bilder\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå Train-Ordner fehlt: {train_path}\")\n",
    "    \n",
    "    if test_path.exists():\n",
    "        print(f\"   ‚úì Test-Ordner: {test_path}\")\n",
    "        for klasse_dir in test_path.iterdir():\n",
    "            if klasse_dir.is_dir():\n",
    "                count = len(list(klasse_dir.glob('*.*')))\n",
    "                total_test += count\n",
    "                print(f\"      {klasse_dir.name:20s}: {count:4d} Bilder\")\n",
    "        print(f\"      {'GESAMT':20s}: {total_test:4d} Bilder\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå Test-Ordner fehlt: {test_path}\")\n",
    "else:\n",
    "    print(f\"   ‚ùå Baumstruktur-Ordner existiert nicht!\")\n",
    "    print(\"      ‚Üí F√ºhren Sie das Training-Notebook aus, um Daten zu entpacken!\")\n",
    "\n",
    "# 4. Vergleich und Empfehlungen\n",
    "print(\"\\n4. Vergleich und Empfehlungen:\")\n",
    "if extracted_path.exists() and baumstruktur_path.exists():\n",
    "    total_baumstruktur = total_train + total_test\n",
    "    if total_extracted > total_baumstruktur:\n",
    "        diff = total_extracted - total_baumstruktur\n",
    "        print(f\"   ‚ö†Ô∏è WARNUNG: {diff} neue Bilder in 'extracted/' gefunden!\")\n",
    "        print(f\"      ‚Üí Extrahierte Bilder: {total_extracted}\")\n",
    "        print(f\"      ‚Üí In Baumstruktur: {total_baumstruktur} ({total_train} Train + {total_test} Test)\")\n",
    "        print(f\"      ‚Üí F√ºhren Sie das Objektextraktions-Notebook aus, um:\")\n",
    "        print(f\"         1. Alle {total_extracted} Bilder zu verarbeiten\")\n",
    "        print(f\"         2. Train/Test Split durchzuf√ºhren (80/20)\")\n",
    "        print(f\"         3. ZIP-Dateien neu zu erstellen\")\n",
    "    elif total_extracted < total_baumstruktur:\n",
    "        diff = total_baumstruktur - total_extracted\n",
    "        print(f\"   ‚ö†Ô∏è HINWEIS: {diff} Bilder mehr in Baumstruktur als in extracted/\")\n",
    "        print(f\"      ‚Üí Dies kann passieren, wenn Bilder mehrfach extrahiert wurden\")\n",
    "        print(f\"      ‚Üí Oder wenn die ZIP-Dateien neuere Daten enthalten\")\n",
    "    else:\n",
    "        print(f\"   ‚úì Alle extrahierten Bilder sind in Train/Test aufgeteilt\")\n",
    "        print(f\"      ‚Üí Extrahierte: {total_extracted} = Train {total_train} + Test {total_test}\")\n",
    "        print(f\"      ‚Üí Verh√§ltnis: {total_train/total_extracted*100:.1f}% Train, {total_test/total_extracted*100:.1f}% Test\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d9eb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# UMFASSENDE DIAGNOSE: Warum sagen alle Modelle nur 1 Klasse vorher?\n",
    "# ============================================================================\n",
    "# Diese Zelle analysiert systematisch alle m√∂glichen Ursachen\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üî¨ UMFASSENDE DIAGNOSE: WARUM SAGEN ALLE MODELLE NUR 1 KLASSE VORHER?\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ============================================================================\n",
    "# 1. PR√úFUNG: Klassenreihenfolge-Mismatch\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"1Ô∏è‚É£ PR√úFUNG: KLASSENREIHENFOLGE-MISMATCH\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if 'class_names' in globals() and 'expected_class_names' in globals():\n",
    "    print(f\"\\nüìã Klassenreihenfolge im Evaluation-Notebook:\")\n",
    "    for i, name in enumerate(class_names):\n",
    "        print(f\"  Index {i}: {name}\")\n",
    "    \n",
    "    print(f\"\\nüìã Erwartete Klassenreihenfolge (aus Training):\")\n",
    "    for i, name in enumerate(expected_class_names):\n",
    "        print(f\"  Index {i}: {name}\")\n",
    "    \n",
    "    if class_names == expected_class_names:\n",
    "        print(\"\\n‚úì Klassenreihenfolge stimmt √ºberein!\")\n",
    "    else:\n",
    "        print(\"\\n‚ùå PROBLEM GEFUNDEN: Klassenreihenfolge stimmt NICHT √ºberein!\")\n",
    "        print(\"   ‚Üí Das ist wahrscheinlich die Hauptursache!\")\n",
    "        print(\"   ‚Üí L√∂sung: Passe 'class_names' im Evaluation-Notebook an\")\n",
    "        print(f\"   ‚Üí Erwartet: {expected_class_names}\")\n",
    "        print(f\"   ‚Üí Aktuell:  {class_names}\")\n",
    "else:\n",
    "    print(\"‚ö† 'class_names' oder 'expected_class_names' nicht definiert\")\n",
    "\n",
    "# ============================================================================\n",
    "# 2. PR√úFUNG: Softmax-Ausgaben analysieren (sind sie wirklich immer gleich?)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"2Ô∏è‚É£ PR√úFUNG: SOFTMAX-AUSGABEN (Wahrscheinlichkeiten)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "available_models = []\n",
    "if 'y_pred_proba1' in globals() and globals()['y_pred_proba1'] is not None:\n",
    "    available_models.append(('Modell 1 (Simple CNN)', 'y_pred_proba1', 'y_pred1'))\n",
    "if 'y_pred_proba2' in globals() and globals()['y_pred_proba2'] is not None:\n",
    "    available_models.append(('Modell 2 (Transfer Learning)', 'y_pred_proba2', 'y_pred2'))\n",
    "if 'y_pred_proba3' in globals() and globals()['y_pred_proba3'] is not None:\n",
    "    available_models.append(('Modell 3 (Standard)', 'y_pred_proba3', 'y_pred3'))\n",
    "\n",
    "if len(available_models) == 0:\n",
    "    print(\"‚ö† Keine Vorhersage-Wahrscheinlichkeiten gefunden!\")\n",
    "    print(\"  Bitte f√ºhren Sie zuerst Zelle 16 (Evaluation) aus.\")\n",
    "else:\n",
    "    for model_name, proba_var, pred_var in available_models:\n",
    "        y_pred_proba = globals()[proba_var]\n",
    "        y_pred = globals()[pred_var]\n",
    "        \n",
    "        print(f\"\\n{model_name}:\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        # Zeige erste 5 Vorhersagen mit Wahrscheinlichkeiten\n",
    "        print(\"\\nüìä Erste 5 Vorhersagen (Wahrscheinlichkeiten):\")\n",
    "        for i in range(min(5, len(y_pred_proba))):\n",
    "            probs = y_pred_proba[i]\n",
    "            pred_idx = y_pred[i]\n",
    "            if 'class_names' in globals():\n",
    "                pred_class = class_names[pred_idx]\n",
    "                print(f\"  Bild {i}: Vorhergesagt = {pred_class} (Index {pred_idx}, Wahrscheinlichkeit: {probs[pred_idx]:.3f})\")\n",
    "                print(f\"    Alle Wahrscheinlichkeiten: {dict(zip(class_names, probs))}\")\n",
    "            else:\n",
    "                print(f\"  Bild {i}: Vorhergesagt = Index {pred_idx}, Wahrscheinlichkeit: {probs[pred_idx]:.3f}\")\n",
    "                print(f\"    Alle Wahrscheinlichkeiten: {probs}\")\n",
    "        \n",
    "        # Pr√ºfe ob alle Vorhersagen gleich sind\n",
    "        unique_predictions = np.unique(y_pred)\n",
    "        print(f\"\\nüìä Vorhersage-Verteilung:\")\n",
    "        print(f\"  Anzahl verschiedene Vorhersagen: {len(unique_predictions)}\")\n",
    "        if len(unique_predictions) == 1:\n",
    "            print(f\"  ‚ùå PROBLEM: Alle Vorhersagen sind gleich (Index {unique_predictions[0]})!\")\n",
    "            if 'class_names' in globals():\n",
    "                print(f\"  ‚Üí Alle Bilder werden als '{class_names[unique_predictions[0]]}' klassifiziert\")\n",
    "        else:\n",
    "            print(f\"  ‚úì Verschiedene Vorhersagen: {unique_predictions}\")\n",
    "            if 'class_names' in globals():\n",
    "                print(f\"  ‚Üí Vorhergesagte Klassen: {[class_names[i] for i in unique_predictions]}\")\n",
    "        \n",
    "        # Pr√ºfe ob die Softmax-Ausgaben sehr √§hnlich sind (Modell ist unsicher)\n",
    "        mean_probs = np.mean(y_pred_proba, axis=0)\n",
    "        std_probs = np.std(y_pred_proba, axis=0)\n",
    "        print(f\"\\nüìä Durchschnittliche Wahrscheinlichkeiten pro Klasse:\")\n",
    "        if 'class_names' in globals():\n",
    "            for i, class_name in enumerate(class_names):\n",
    "                print(f\"  {class_name:20s}: {mean_probs[i]:.3f} ¬± {std_probs[i]:.3f}\")\n",
    "        else:\n",
    "            for i in range(len(mean_probs)):\n",
    "                print(f\"  Klasse {i}: {mean_probs[i]:.3f} ¬± {std_probs[i]:.3f}\")\n",
    "        \n",
    "        # Pr√ºfe ob eine Klasse immer die h√∂chste Wahrscheinlichkeit hat\n",
    "        max_probs = np.max(y_pred_proba, axis=1)\n",
    "        mean_max_prob = np.mean(max_probs)\n",
    "        print(f\"\\nüìä Durchschnittliche maximale Wahrscheinlichkeit: {mean_max_prob:.3f}\")\n",
    "        if mean_max_prob < 0.5:\n",
    "            print(f\"  ‚ö† Warnung: Niedrige maximale Wahrscheinlichkeit - Modell ist unsicher\")\n",
    "        elif mean_max_prob > 0.95:\n",
    "            print(f\"  ‚úì Hohe maximale Wahrscheinlichkeit - Modell ist sehr sicher\")\n",
    "\n",
    "# ============================================================================\n",
    "# 3. PR√úFUNG: Datenverteilung (sind die Testdaten ausgewogen?)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"3Ô∏è‚É£ PR√úFUNG: DATENVERTEILUNG\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if 'y_true1' in globals() and globals()['y_true1'] is not None:\n",
    "    y_true = globals()['y_true1']\n",
    "    \n",
    "    if 'class_names' in globals():\n",
    "        y_true_labels = np.array(class_names)[y_true]\n",
    "        unique_true, counts_true = np.unique(y_true_labels, return_counts=True)\n",
    "        \n",
    "        print(\"\\nüìä Verteilung der tats√§chlichen Labels (Testdaten):\")\n",
    "        print(\"-\" * 70)\n",
    "        total = len(y_true)\n",
    "        for true_class, count in zip(unique_true, counts_true):\n",
    "            percentage = (count / total) * 100\n",
    "            print(f\"  {true_class:20s}: {count:3d} Bilder ({percentage:5.1f}%)\")\n",
    "        \n",
    "        # Pr√ºfe ob Daten ausgewogen sind\n",
    "        if len(counts_true) > 0:\n",
    "            max_count = np.max(counts_true)\n",
    "            min_count = np.min(counts_true)\n",
    "            imbalance_ratio = max_count / min_count if min_count > 0 else float('inf')\n",
    "            print(f\"\\nüìä Ausgewogenheit:\")\n",
    "            print(f\"  Verh√§ltnis gr√∂√üte/kleinste Klasse: {imbalance_ratio:.2f}\")\n",
    "            if imbalance_ratio > 2.0:\n",
    "                print(f\"  ‚ö† Warnung: Daten sind unausgewogen (Verh√§ltnis > 2.0)\")\n",
    "            else:\n",
    "                print(f\"  ‚úì Daten sind relativ ausgewogen\")\n",
    "else:\n",
    "    print(\"‚ö† Keine Testdaten-Labels gefunden\")\n",
    "\n",
    "# ============================================================================\n",
    "# 4. PR√úFUNG: Modell-Architektur (sind die Modelle korrekt aufgebaut?)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"4Ô∏è‚É£ PR√úFUNG: MODELL-ARCHITEKTUR\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "model_vars = []\n",
    "if 'loaded_model1' in globals():\n",
    "    model_vars.append(('Modell 1 (Simple CNN)', 'loaded_model1'))\n",
    "if 'loaded_model2' in globals():\n",
    "    model_vars.append(('Modell 2 (Transfer Learning)', 'loaded_model2'))\n",
    "if 'loaded_model3' in globals():\n",
    "    model_vars.append(('Modell 3 (Standard)', 'loaded_model3'))\n",
    "\n",
    "if len(model_vars) == 0:\n",
    "    print(\"‚ö† Keine Modelle geladen!\")\n",
    "else:\n",
    "    for model_name, model_var in model_vars:\n",
    "        model = globals()[model_var]\n",
    "        print(f\"\\n{model_name}:\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        # Pr√ºfe Output-Layer\n",
    "        output_layer = model.layers[-1]\n",
    "        print(f\"  Output-Layer: {output_layer.name}\")\n",
    "        print(f\"  Output-Aktivierung: {output_layer.activation.__name__ if hasattr(output_layer.activation, '__name__') else str(output_layer.activation)}\")\n",
    "        print(f\"  Output-Shape: {output_layer.output_shape}\")\n",
    "        \n",
    "        if hasattr(output_layer, 'units'):\n",
    "            print(f\"  Anzahl Output-Neuronen: {output_layer.units}\")\n",
    "            if 'class_names' in globals():\n",
    "                expected_units = len(class_names)\n",
    "                if output_layer.units == expected_units:\n",
    "                    print(f\"  ‚úì Anzahl Output-Neuronen stimmt mit Anzahl Klassen √ºberein ({expected_units})\")\n",
    "                else:\n",
    "                    print(f\"  ‚ùå PROBLEM: Anzahl Output-Neuronen ({output_layer.units}) stimmt nicht mit Anzahl Klassen ({expected_units}) √ºberein!\")\n",
    "        \n",
    "        # Pr√ºfe ob Modell trainierbar ist\n",
    "        trainable_count = sum(1 for layer in model.layers if layer.trainable)\n",
    "        total_count = len(model.layers)\n",
    "        print(f\"  Trainierbare Layer: {trainable_count}/{total_count}\")\n",
    "        if trainable_count == 0:\n",
    "            print(f\"  ‚ö† Warnung: Keine trainierbaren Layer - Modell kann nicht lernen!\")\n",
    "\n",
    "# ============================================================================\n",
    "# 5. ZUSAMMENFASSUNG & L√ñSUNGSVORSCHL√ÑGE\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"5Ô∏è‚É£ ZUSAMMENFASSUNG & L√ñSUNGSVORSCHL√ÑGE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nüìã M√∂gliche Ursachen und L√∂sungen:\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "print(\"\\n1. KLASSENREIHENFOLGE-MISMATCH:\")\n",
    "print(\"   ‚Üí Problem: Reihenfolge im Training ‚â† Reihenfolge in Evaluation\")\n",
    "print(\"   ‚Üí L√∂sung: Passe 'class_names' im Evaluation-Notebook an die Training-Reihenfolge an\")\n",
    "print(\"   ‚Üí Siehe Zelle 5 (Modell-Laden) f√ºr die erwartete Reihenfolge\")\n",
    "\n",
    "print(\"\\n2. MODELL LERNT NICHT RICHTIG:\")\n",
    "print(\"   ‚Üí Problem: Zu wenig Daten, falsche Hyperparameter, zu aggressive Data Augmentation\")\n",
    "print(\"   ‚Üí L√∂sung: Pr√ºfe Training-Notebook:\")\n",
    "print(\"     - Sind genug Epochen trainiert? (mindestens 50-100)\")\n",
    "print(\"     - Ist die Learning Rate zu hoch/niedrig?\")\n",
    "print(\"     - Ist Data Augmentation zu aggressiv?\")\n",
    "print(\"     - Sind Class Weights zu extrem?\")\n",
    "\n",
    "print(\"\\n3. SOFTMAX-AUSGABEN SIND IMMER GLEICH:\")\n",
    "print(\"   ‚Üí Problem: Modell gibt immer die gleiche Wahrscheinlichkeit aus\")\n",
    "print(\"   ‚Üí L√∂sung: Pr√ºfe ob Modell √ºberhaupt trainiert wurde (Training-Historie)\")\n",
    "print(\"     - Val_Accuracy sollte steigen\")\n",
    "print(\"     - Loss sollte sinken\")\n",
    "\n",
    "print(\"\\n4. DATEN SIND ZU UN√ÑHNLICH:\")\n",
    "print(\"   ‚Üí Problem: Testdaten unterscheiden sich zu stark von Trainingsdaten\")\n",
    "print(\"   ‚Üí L√∂sung: Pr√ºfe ob Testdaten genauso verarbeitet werden wie Trainingsdaten\")\n",
    "print(\"     - Gleiche Bildgr√∂√üe?\")\n",
    "print(\"     - Gleiche Normalisierung?\")\n",
    "print(\"     - Gleiche Preprocessing-Schritte?\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úì DIAGNOSE ABGESCHLOSSEN\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109450b4",
   "metadata": {},
   "source": [
    "## üí° **KONKRETE L√ñSUNGSVORSCHL√ÑGE F√úR DAS TRAINING**\n",
    "\n",
    "Falls die Diagnose zeigt, dass das Modell nicht richtig lernt, hier konkrete Anpassungen f√ºr das Training-Notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40610500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# KONKRETE L√ñSUNGSVORSCHL√ÑGE F√úR DAS TRAINING\n",
    "# ============================================================================\n",
    "# Diese Zelle zeigt konkrete Anpassungen, die im Training-Notebook gemacht werden sollten\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üí° KONKRETE L√ñSUNGSVORSCHL√ÑGE F√úR DAS TRAINING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üîß ANPASSUNGEN F√úR semesterarbeit-training.ipynb\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n1Ô∏è‚É£ LEARNING RATE ANPASSEN:\")\n",
    "print(\"-\" * 70)\n",
    "print(\"\"\"\n",
    "Problem: Learning Rate k√∂nnte zu hoch oder zu niedrig sein\n",
    "‚Üí Zu hoch: Modell lernt nicht stabil, springt zwischen L√∂sungen\n",
    "‚Üí Zu niedrig: Modell lernt zu langsam oder gar nicht\n",
    "\n",
    "L√∂sung in train_model.py oder direkt im Notebook:\n",
    "  # F√ºr Transfer Learning (MobileNetV2):\n",
    "  optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)  # Start mit 0.0001\n",
    "  # Falls Modell nicht lernt, versuche:\n",
    "  # - 0.0005 (schneller, aber weniger stabil)\n",
    "  # - 0.00005 (langsamer, aber stabiler)\n",
    "  \n",
    "  # F√ºr Simple CNN:\n",
    "  optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)  # Start mit 0.001\n",
    "  # Falls Modell nicht lernt, versuche:\n",
    "  # - 0.005 (schneller)\n",
    "  # - 0.0005 (langsamer, aber stabiler)\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n2Ô∏è‚É£ DATA AUGMENTATION REDUZIEREN:\")\n",
    "print(\"-\" * 70)\n",
    "print(\"\"\"\n",
    "Problem: Zu aggressive Data Augmentation kann das Modell verwirren\n",
    "‚Üí Modell sieht zu viele Variationen und lernt nicht die Grundmerkmale\n",
    "\n",
    "L√∂sung in model_transfer_learning.py oder model_simple_cnn.py:\n",
    "  # Reduziere Augmentation-Parameter:\n",
    "  data_augmentation = tf.keras.Sequential([\n",
    "      layers.RandomFlip(\"horizontal\"),  # OK\n",
    "      layers.RandomRotation(0.1),       # Reduziert von 0.2 auf 0.1\n",
    "      layers.RandomZoom(0.1),           # Reduziert von 0.2 auf 0.1\n",
    "      layers.RandomBrightness(0.1),     # Reduziert von 0.2 auf 0.1\n",
    "      layers.RandomContrast(0.1),       # Reduziert von 0.2 auf 0.1\n",
    "  ])\n",
    "  \n",
    "  # ODER: Deaktiviere Augmentation komplett f√ºr Test:\n",
    "  # data_augmentation = tf.keras.Sequential([])  # Leer = keine Augmentation\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n3Ô∏è‚É£ CLASS WEIGHTS ANPASSEN:\")\n",
    "print(\"-\" * 70)\n",
    "print(\"\"\"\n",
    "Problem: Class Weights k√∂nnten zu extrem sein\n",
    "‚Üí Eine Klasse wird zu stark gewichtet, andere zu schwach\n",
    "\n",
    "L√∂sung in train_model.py (calculate_class_weights Funktion):\n",
    "  # Aktuelle Formel (inverse Frequenz):\n",
    "  weight = total_samples / (len(class_names) * count)\n",
    "  \n",
    "  # Alternative: Square-root weighting (weniger extrem):\n",
    "  weight = np.sqrt(total_samples / (len(class_names) * count))\n",
    "  \n",
    "  # ODER: Deaktiviere Class Weights komplett:\n",
    "  # class_weights = None  # Keine Gewichtung\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n4Ô∏è‚É£ MEHR EPOCHE TRAINIEREN:\")\n",
    "print(\"-\" * 70)\n",
    "print(\"\"\"\n",
    "Problem: Modell wurde nicht lange genug trainiert\n",
    "‚Üí Modell hat noch nicht genug gelernt\n",
    "\n",
    "L√∂sung in train_model.py oder Notebook:\n",
    "  # Erh√∂he Anzahl Epochen:\n",
    "  epochs = 200  # Statt 100\n",
    "  \n",
    "  # Erh√∂he Patience f√ºr EarlyStopping:\n",
    "  patience = 150  # Statt 100 (warte l√§nger auf Verbesserung)\n",
    "  \n",
    "  # ODER: Deaktiviere EarlyStopping tempor√§r:\n",
    "  # early_stopping_callback = None  # Trainiere alle Epochen\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n5Ô∏è‚É£ DROPOUT REDUZIEREN:\")\n",
    "print(\"-\" * 70)\n",
    "print(\"\"\"\n",
    "Problem: Zu viel Dropout kann das Lernen verhindern\n",
    "‚Üí Modell kann keine Muster lernen, weil zu viele Neuronen deaktiviert werden\n",
    "\n",
    "L√∂sung in model_transfer_learning.py:\n",
    "  # Reduziere Dropout:\n",
    "  x = layers.Dropout(0.3)(x)  # Statt 0.5\n",
    "  x = layers.Dropout(0.2)(x)  # Statt 0.3\n",
    "  \n",
    "  # ODER: Entferne Dropout komplett f√ºr Test:\n",
    "  # x = layers.Dense(128, activation='relu')(x)\n",
    "  # # Kein Dropout\n",
    "  # x = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n6Ô∏è‚É£ FINE-TUNING ANPASSEN:\")\n",
    "print(\"-\" * 70)\n",
    "print(\"\"\"\n",
    "Problem: Base Model (MobileNetV2) ist gefroren oder zu fr√ºh aufgetaut\n",
    "‚Üí Modell kann nicht lernen, weil Basis-Gewichte nicht angepasst werden\n",
    "\n",
    "L√∂sung in train_model.py:\n",
    "  # F√ºr Transfer Learning:\n",
    "  # Option 1: Fine-Tuning von Anfang an (alle Layer trainierbar)\n",
    "  model = make_model_transfer_learning(\n",
    "      image_size=image_size,\n",
    "      num_classes=num_classes,\n",
    "      fine_tune=True  # Alle Layer trainierbar\n",
    "  )\n",
    "  \n",
    "  # Option 2: Zuerst Top-Layer trainieren, dann Fine-Tuning\n",
    "  # Schritt 1: Top-Layer trainieren (fine_tune=False)\n",
    "  # Schritt 2: Base Model auftauen (base_model.trainable = True)\n",
    "  # Schritt 3: Mit niedrigerer Learning Rate weiter trainieren\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n7Ô∏è‚É£ BATCH SIZE ANPASSEN:\")\n",
    "print(\"-\" * 70)\n",
    "print(\"\"\"\n",
    "Problem: Batch Size k√∂nnte zu gro√ü oder zu klein sein\n",
    "‚Üí Zu gro√ü: Modell lernt zu langsam\n",
    "‚Üí Zu klein: Modell lernt instabil\n",
    "\n",
    "L√∂sung im Notebook:\n",
    "  # Reduziere Batch Size:\n",
    "  batch_size = 16  # Statt 32 (mehr Updates pro Epoche)\n",
    "  \n",
    "  # ODER: Erh√∂he Batch Size:\n",
    "  batch_size = 64  # Statt 32 (stabileres Training)\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìã CHECKLISTE F√úR TRAINING-ANPASSUNGEN\")\n",
    "print(\"=\"*70)\n",
    "print(\"\"\"\n",
    "‚ñ° 1. Pr√ºfe Training-Historie: Steigt val_accuracy? Sinkt loss?\n",
    "‚ñ° 2. Pr√ºfe Klassenreihenfolge: Stimmt sie zwischen Training und Evaluation?\n",
    "‚ñ° 3. Reduziere Data Augmentation (weniger aggressive Transformationen)\n",
    "‚ñ° 4. Passe Learning Rate an (versuche 0.0001 f√ºr Transfer Learning)\n",
    "‚ñ° 5. Reduziere Dropout (0.3 statt 0.5)\n",
    "‚ñ° 6. Erh√∂he Anzahl Epochen (200 statt 100)\n",
    "‚ñ° 7. Pr√ºfe Class Weights (sind sie zu extrem?)\n",
    "‚ñ° 8. Stelle sicher, dass Fine-Tuning aktiviert ist (fine_tune=True)\n",
    "‚ñ° 9. Pr√ºfe ob genug Daten vorhanden sind (mindestens 50-100 Bilder pro Klasse)\n",
    "‚ñ° 10. Pr√ºfe ob Testdaten genauso verarbeitet werden wie Trainingsdaten\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úì L√ñSUNGSVORSCHL√ÑGE ABGESCHLOSSEN\")\n",
    "print(\"=\"*70)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5200216,
     "sourceId": 8675720,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8611387,
     "sourceId": 13557510,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 88255,
     "modelInstanceId": 64165,
     "sourceId": 76355,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 29.517292,
   "end_time": "2025-10-30T17:56:35.066105",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-30T17:56:05.548813",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
